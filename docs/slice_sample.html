
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>gpyreg.slice_sample &#8212; GPyReg  documentation</title>
    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="_static/alabaster.css" />
    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="prev" title="gpyreg.gaussian_process" href="gaussian_process.html" />
   
  <link rel="stylesheet" href="_static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head><body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <section id="gpyreg-slice-sample">
<h1>gpyreg.slice_sample<a class="headerlink" href="#gpyreg-slice-sample" title="Permalink to this headline">¶</a></h1>
<section id="module-gpyreg.slice_sample">
<span id="slice-sample-module"></span><h2><code class="xref py py-mod docutils literal notranslate"><span class="pre">slice_sample</span></code> Module<a class="headerlink" href="#module-gpyreg.slice_sample" title="Permalink to this headline">¶</a></h2>
<p>Module for slice sampling.</p>
<dl class="py class">
<dt class="sig sig-object py" id="gpyreg.slice_sample.SliceSampler">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">gpyreg.slice_sample.</span></span><span class="sig-name descname"><span class="pre">SliceSampler</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">log_f</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">x0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">widths</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">LB</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">UB</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">options</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#gpyreg.slice_sample.SliceSampler" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>Class for drawing random samples from a target distribution with a
given log probability density function using the coordinate-wise
slice sampling method.</p>
<dl class="field-list">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl>
<dt><strong>log_f</strong><span class="classifier">callable</span></dt><dd><p>The log pdf of the target distribution. It takes one argument as
input that has the same type and size as <code class="docutils literal notranslate"><span class="pre">x0</span></code> and returns the
target log density function (minus a constant; that is, the
normalization constant of the pdf need not be known).</p>
<p>Note that <code class="docutils literal notranslate"><span class="pre">log_f</span></code> can return either a scalar
(the value of the log probability density at <code class="docutils literal notranslate"><span class="pre">x</span></code>) or a row vector
(the value of the log probability density at <code class="docutils literal notranslate"><span class="pre">x</span></code> for each data
point; each column corresponds to a different data point). In the
latter case, the total log pdf is obtained by summing the log pdf
per each individual data point. Also, <code class="docutils literal notranslate"><span class="pre">f_vals</span></code> in the object
returned by <code class="docutils literal notranslate"><span class="pre">sample</span></code> is a matrix (each row corresponds to a
sampled point, each column to a different data point). Knowing the
log pdf of the sampled points per each data point can be useful to
compute estimates of predictive error such as the widely applicable
information criterion (WAIC); see <a class="reference internal" href="#r6f8715ba5828-3" id="id1">[3]</a>.</p>
</dd>
<dt><strong>x0</strong><span class="classifier">ndarray, shape (n,)</span></dt><dd><p>Initial value of the random sample sequence. It must be within the
domain of the target distribution. The number of independent
variables is ‘n’.</p>
</dd>
<dt><strong>widths</strong><span class="classifier">array_like, optional</span></dt><dd><p>A parameter for typical widths. Either a scalar or a 1D array.
If it is a scalar, all dimensions are assumed to have the same
typical widths. If it is a 1D array, each element of the array
is the typical width of the marginal target distribution in that
dimension. The default value of <code class="docutils literal notranslate"><span class="pre">widths[i]</span></code> is <code class="docutils literal notranslate"><span class="pre">(UB[i]-LB[i])/2</span></code>
if the <code class="docutils literal notranslate"><span class="pre">i</span></code>-th bounds are finite, or 10 otherwise. By default we
use an adaptive widths method during the burn-in period, so
the choice of typical widths is not crucial.</p>
</dd>
<dt><strong>LB</strong><span class="classifier">array_like, optional</span></dt><dd><p>An array of lower bounds on the domain of the target density
function, which is assumed to be zero outside the range
<code class="docutils literal notranslate"><span class="pre">LB</span> <span class="pre">&lt;=</span> <span class="pre">x</span> <span class="pre">&lt;=</span> <span class="pre">UB</span></code>. If not given we assume no lower bounds.
Set <code class="docutils literal notranslate"><span class="pre">LB[i]</span> <span class="pre">=</span> <span class="pre">-inf</span></code> if <code class="docutils literal notranslate"><span class="pre">x[i]</span></code> is unbounded below. If
<code class="docutils literal notranslate"><span class="pre">LB[i]</span> <span class="pre">==</span> <span class="pre">UB[i]</span></code>, the variable is assumed to be fixed on
that dimension.</p>
</dd>
<dt><strong>UB</strong><span class="classifier">array_like, optional</span></dt><dd><p>An array of upper bounds on the domain of the target density
function, which is assumed to be zero outside the range
<code class="docutils literal notranslate"><span class="pre">LB</span> <span class="pre">&lt;=</span> <span class="pre">x</span> <span class="pre">&lt;=</span> <span class="pre">UB</span></code>. If not given we assume no upper bounds.
Set <code class="docutils literal notranslate"><span class="pre">UB[i]</span> <span class="pre">=</span> <span class="pre">inf</span></code> if <code class="docutils literal notranslate"><span class="pre">x[i]</span></code> is unbounded above. If
<code class="docutils literal notranslate"><span class="pre">LB[i]</span> <span class="pre">==</span> <span class="pre">UB[i]</span></code>, the variable is assumed to be fixed on that
dimension.</p>
</dd>
<dt><strong>options</strong><span class="classifier">dict, optional</span></dt><dd><p>A dictionary of sampler options. The possible options are:</p>
<blockquote>
<div><dl class="simple">
<dt><strong>step_out</strong><span class="classifier">bool, defaults to False</span></dt><dd><p>If set to true, performs the stepping-out action when
the current window does not bracket the probability density.
For details see <a class="reference internal" href="#r6f8715ba5828-1" id="id2">[1]</a>.</p>
</dd>
<dt><strong>display</strong><span class="classifier">{‘off’, ‘summary’, ‘full’}, defaults to ‘full’</span></dt><dd><p>Defines the level of display.</p>
</dd>
<dt><strong>log_prior</strong><span class="classifier">callable, optional</span></dt><dd><p>Allows the user to specify a prior over <code class="docutils literal notranslate"><span class="pre">x</span></code>. The function
<code class="docutils literal notranslate"><span class="pre">log_prior</span></code> takes one argument as input that has the same
type and size as <code class="docutils literal notranslate"><span class="pre">x0</span></code> and returns the log prior density
function at X. The generated samples will be then drawn
from the log density <code class="docutils literal notranslate"><span class="pre">log_f</span> <span class="pre">+</span> <span class="pre">log_prior</span></code>.</p>
</dd>
<dt><strong>adaptive</strong><span class="classifier">bool, defaults to True</span></dt><dd><p>Specifies whether to adapt <code class="docutils literal notranslate"><span class="pre">widths</span></code> at the end of the
burn-in period based on the samples obtained so far.
Disabling this works best if we already have good estimates.</p>
</dd>
<dt><strong>diagnostics</strong><span class="classifier">bool, defaults to True</span></dt><dd><p>Specifies whether convergence diagnostics are performed at
the end of the run. The diagnostic tests are from <a class="reference internal" href="#r6f8715ba5828-4" id="id3">[4]</a>.</p>
</dd>
</dl>
</div></blockquote>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">Notes</p>
<p>Inspired by a MATLAB implementation of slice sampling by Iain Murray.
See pseudo-code in <a class="reference internal" href="#r6f8715ba5828-2" id="id4">[2]</a>.</p>
<p class="rubric">References</p>
<dl class="citation">
<dt class="label" id="r6f8715ba5828-1"><span class="brackets"><a class="fn-backref" href="#id2">1</a></span></dt>
<dd><p>R. Neal (2003), Slice Sampling, Annals of Statistics,
31(3), p705-67.</p>
</dd>
<dt class="label" id="r6f8715ba5828-2"><span class="brackets"><a class="fn-backref" href="#id4">2</a></span></dt>
<dd><p>D. J. MacKay (2003), Information theory, inference and learning
algorithms, Cambridge university press, p374-7.</p>
</dd>
<dt class="label" id="r6f8715ba5828-3"><span class="brackets"><a class="fn-backref" href="#id1">3</a></span></dt>
<dd><p>S. Watanabe (2010), Asymptotic equivalence of Bayes cross
validation and widely applicable information criterion in singular
learning theory, The Journal of Machine Learning Research,
11, p3571-94.</p>
</dd>
<dt class="label" id="r6f8715ba5828-4"><span class="brackets"><a class="fn-backref" href="#id3">4</a></span></dt>
<dd><p>A. Gelman, et al (2013), Bayesian data analysis. Vol. 2.
Boca Raton, FL, USA: Chapman &amp; Hall/CRC.</p>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="gpyreg.slice_sample.SliceSampler.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">log_f</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">x0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">widths</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">LB</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">UB</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">options</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#gpyreg.slice_sample.SliceSampler.__init__" title="Permalink to this definition">¶</a></dt>
<dd><p>Initialize self.  See help(type(self)) for accurate signature.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="gpyreg.slice_sample.SliceSampler.sample">
<span class="sig-name descname"><span class="pre">sample</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">N</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">thin</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">burn</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#gpyreg.slice_sample.SliceSampler.sample" title="Permalink to this definition">¶</a></dt>
<dd><p>Samples an arbitrary number of points from the distribution.</p>
<dl class="field-list">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>N</strong><span class="classifier">int</span></dt><dd><p>The number of samples to return.</p>
</dd>
<dt><strong>thin</strong><span class="classifier">int, optional</span></dt><dd><p>The thinning parameter will omit <code class="docutils literal notranslate"><span class="pre">thin-1</span></code> out of <code class="docutils literal notranslate"><span class="pre">thin</span></code> values
in the generated sequence (after burn-in).</p>
</dd>
<dt><strong>burn</strong><span class="classifier">int, optional</span></dt><dd><p>The burn parameter omits the first <code class="docutils literal notranslate"><span class="pre">burn</span></code> points before starting
recording points for the generated sequence.
In case this is the first time sampling, the default value of burn
is <code class="docutils literal notranslate"><span class="pre">round(N/3)</span></code> (that is, one third of the number of recorded
samples), while otherwise it is 0.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl>
<dt><strong>res</strong><span class="classifier">dict</span></dt><dd><p>The sampling result represented as a dictionary with attributes</p>
<blockquote>
<div><dl>
<dt><strong>samples</strong><span class="classifier">array_like</span></dt><dd><p>The actual sampled points.</p>
</dd>
<dt><strong>f_vals</strong><span class="classifier">array_like</span></dt><dd><p>The sequence of values of the target log pdf at the sampled
points. If a prior is specified in <code class="docutils literal notranslate"><span class="pre">log_prior</span></code>, then
<code class="docutils literal notranslate"><span class="pre">f_vals</span></code> does NOT include the contribution of the prior.</p>
</dd>
<dt><strong>exit_flag</strong><span class="classifier">{ 1, 0, -1, -2, -3 }</span></dt><dd><p>Possible values and the corresponding exit conditions are</p>
<blockquote>
<div><dl class="simple">
<dt>1, Target number of recorded samples reached,</dt><dd><p>with no explicit violation of convergence
(this does not ensure convergence).</p>
</dd>
<dt>0, Target number of recorded samples reached,</dt><dd><p>convergence status is unknown (no diagnostics have
been run).</p>
</dd>
<dt>-1, No explicit violation of convergence detected, but</dt><dd><p>the number of effective (independent) samples in the
sampled sequence is much lower than the number of
requested samples N for at least one dimension.</p>
</dd>
<dt>-2, Detected probable lack of convergence of the sampling</dt><dd><p>procedure.</p>
</dd>
<dt>-3, Detected lack of convergence of the sampling</dt><dd><p>procedure.</p>
</dd>
</dl>
</div></blockquote>
</dd>
<dt><strong>log_priors</strong><span class="classifier">array_like</span></dt><dd><p>The sequence of the values of the log prior at the sampled
points.</p>
</dd>
<dt><strong>R</strong><span class="classifier">array_like</span></dt><dd><p>Estimate of the potential scale reduction factor in each
dimension.</p>
</dd>
<dt><strong>eff_N</strong><span class="classifier">array_like</span></dt><dd><p>Estimate of the effective number of samples in each
dimension.</p>
</dd>
</dl>
</div></blockquote>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
</section>


          </div>
          
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
<h1 class="logo"><a href="index.html">GPyReg</a></h1>








<h3>Navigation</h3>
<p class="caption"><span class="caption-text">Contents:</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="modules.html">gpyreg</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="covariance_functions.html">gpyreg.covariance_functions</a></li>
<li class="toctree-l2"><a class="reference internal" href="mean_functions.html">gpyreg.mean_functions</a></li>
<li class="toctree-l2"><a class="reference internal" href="noise_functions.html">gpyreg.noise_functions</a></li>
<li class="toctree-l2"><a class="reference internal" href="gaussian_process.html">gpyreg.gaussian_process</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">gpyreg.slice_sample</a></li>
</ul>
</li>
</ul>

<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="index.html">Documentation overview</a><ul>
  <li><a href="modules.html">gpyreg</a><ul>
      <li>Previous: <a href="gaussian_process.html" title="previous chapter">gpyreg.gaussian_process</a></li>
  </ul></li>
  </ul></li>
</ul>
</div>
<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" />
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script>$('#searchbox').show(0);</script>








        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &copy;2021, Machine and Human Intelligence research group (PI: Luigi Acerbi, University of Helsinki).
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 4.0.3</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.12</a>
      
      |
      <a href="_sources/slice_sample.rst.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
  </body>
</html>